import streamlit as st
import pandas as pd
import numpy as np
from sklearn.metrics import r2_score, accuracy_score
import matplotlib.pyplot as plt

# –ò–º–ø–æ—Ä—Ç CatBoost
try:
    from catboost import CatBoostRegressor, CatBoostClassifier
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False
    st.warning("‚ö†Ô∏è CatBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install catboost")

def create_boosting_interface():
    st.subheader('üöÄ CatBoost –¥–ª—è –¥–æ–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤')
    st.caption('CatBoost –¥–ª—è –ø—Ä—è–º–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, COLL) –±–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏')
    
    if 'merged_data' not in st.session_state or st.session_state.merged_data.empty:
        st.warning('‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞–∑–¥–µ–ª–µ "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ"')
        return
    
    df = st.session_state.merged_data.copy()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader('–ù–∞—Å—Ç—Ä–æ–π–∫–∏')
        task_type = st.selectbox('–¢–∏–ø –∑–∞–¥–∞—á–∏', ['regression', 'classification'])
        n_estimators = 50  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    
    with col2:
        st.subheader('–ü—Ä–∏–∑–Ω–∞–∫–∏')
        numeric_columns = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col]) and col not in ['group_number', 'top', 'bottom', 'h', 'DEPTH', 'depth', 'COLL']]
        
        if not numeric_columns:
            st.error('‚ùå –ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')
            return
        
        selected_features = st.multiselect('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏', numeric_columns, default=numeric_columns[:5])
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        excluded_columns = [col for col in df.columns if col in ['group_number', 'top', 'bottom', 'h', 'DEPTH', 'depth', 'COLL']]
        if excluded_columns:
            st.caption(f'üö´ –ò—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {", ".join(excluded_columns)}')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç COLL
        potential_targets = [col for col in numeric_columns if col not in selected_features]
        categorical_columns = [col for col in df.columns if not pd.api.types.is_numeric_dtype(df[col]) and col not in ['group_number', 'well']]
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞
        collector_columns = [col for col in categorical_columns if any(keyword in col.lower() for keyword in ['coll', '–∫–æ–ª–ª–µ–∫—Ç–æ—Ä', 'collector'])]
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–ø—Ü–∏–π –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        target_options = []
        default_index = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º COLL –µ—Å–ª–∏ –µ—Å—Ç—å
        if 'COLL' in df.columns:
            target_options.append('COLL')
            default_index = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        for col in collector_columns:
            if col != 'COLL' and col not in target_options:
                target_options.append(col)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        for col in potential_targets:
            if col not in target_options:
                target_options.append(col)
        
        if target_options:
            target_column = st.selectbox('–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è', target_options, index=default_index)
            if target_column == 'COLL':
                st.info("üéØ –í—ã–±—Ä–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ COLL (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
            else:
                st.info(f"üéØ –í—ã–±—Ä–∞–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {target_column}")
        else:
            st.error('‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö')
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ COLL –∏ —Å–æ–∑–¥–∞–µ–º COLL_advance
        if 'COLL' in df.columns:
            st.info("üìä –ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ COLL. –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ COLL_advance —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –¥–ª—è nan –∑–Ω–∞—á–µ–Ω–∏–π.")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ COLL
            coll_stats = df['COLL'].value_counts(dropna=False)
            st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ COLL:**")
            st.write(coll_stats)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ nan –∑–Ω–∞—á–µ–Ω–∏–π
            nan_count = df['COLL'].isna().sum()
            total_count = len(df)
            st.write(f"**NaN –∑–Ω–∞—á–µ–Ω–∏–π –≤ COLL:** {nan_count} –∏–∑ {total_count} ({nan_count/total_count*100:.1f}%)")
        else:
            st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ COLL –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
    
    if st.button('üéØ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å'):
        if not selected_features:
            st.error('‚ùå –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏')
            return
        
        if not CATBOOST_AVAILABLE:
            st.error('‚ùå CatBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install catboost')
            return
        
        with st.spinner('–û–±—É—á–µ–Ω–∏–µ CatBoost –º–æ–¥–µ–ª–∏...'):
            try:
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è COLL
                if target_column == 'COLL' and 'COLL' in df.columns:
                    # –û–±—É—á–∞–µ–º—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –Ω–µ-nan –∑–Ω–∞—á–µ–Ω–∏—è—Ö COLL
                    train_mask = df['COLL'].notna()
                    train_data = df[train_mask].copy()
                    
                    if len(train_data) == 0:
                        st.error('‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è - –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è COLL —Ä–∞–≤–Ω—ã NaN')
                        return
                    
                    st.info(f'üìä –û–±—É—á–∞–µ–º—Å—è –Ω–∞ {len(train_data)} —Ç–æ—á–∫–∞—Ö —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ COLL')
                    
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                    X_train = train_data[selected_features].fillna(train_data[selected_features].median())
                    y_train = train_data['COLL']
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                    unique_values = y_train.nunique()
                    if unique_values < 2:
                        st.warning(f'‚ö†Ô∏è COLL —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ: {y_train.iloc[0]}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–∏–π.')
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–∏–π –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
                        similarity_method = st.selectbox(
                            '–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–∏–π:',
                            ['–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ', '–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ', '–ú–∞–Ω—Ö—ç—Ç—Ç–µ–Ω—Å–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ', '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞', 'One-Class SVM', '–ò–∑–æ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –ª–µ—Å']
                        )
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–µ—Ç–æ–¥–∞
                        st.info("""
                        **üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–µ—Ç–æ–¥–∞:**
                        - **–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ**: –õ—É—á—à–µ –¥–ª—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–∞—Å—à—Ç–∞–±–∞
                        - **–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ**: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥, —Ö–æ—Ä–æ—à–æ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                        - **–ú–∞–Ω—Ö—ç—Ç—Ç–µ–Ω—Å–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ**: –£—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º, –ª—É—á—à–µ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        - **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞**: –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
                        - **One-Class SVM**: –ù–∞—Ö–æ–¥–∏—Ç –≥—Ä–∞–Ω–∏—Ü—ã "–Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö" –æ–±—ä–µ–∫—Ç–æ–≤, —Ö–æ—Ä–æ—à–æ –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–π
                        - **–ò–∑–æ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –ª–µ—Å**: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –±—ã—Å—Ç—Ä–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
                        """)
                        
                        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                        X_all = df[selected_features].fillna(df[selected_features].median())
                        y_all = df['COLL']
                        
                        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
                        from sklearn.preprocessing import StandardScaler
                        scaler = StandardScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_all_scaled = scaler.transform(X_all)
                        
                        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ COLL
                        nan_mask = df['COLL'].isna()
                        predictions = np.zeros(len(X_all_scaled))
                        
                        if similarity_method == '–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ':
                            from sklearn.metrics.pairwise import cosine_similarity
                            similarities = cosine_similarity(X_all_scaled[nan_mask], X_train_scaled)
                            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
                            max_similarities = np.max(similarities, axis=1)
                            predictions[nan_mask] = max_similarities
                            
                        elif similarity_method == '–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ':
                            from sklearn.metrics.pairwise import euclidean_distances
                            distances = euclidean_distances(X_all_scaled[nan_mask], X_train_scaled)
                            # –ë–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å)
                            min_distances = np.min(distances, axis=1)
                            predictions[nan_mask] = 1 / (1 + min_distances)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–∂–µ—Å—Ç—å
                            
                        elif similarity_method == '–ú–∞–Ω—Ö—ç—Ç—Ç–µ–Ω—Å–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ':
                            from sklearn.metrics.pairwise import manhattan_distances
                            distances = manhattan_distances(X_all_scaled[nan_mask], X_train_scaled)
                            min_distances = np.min(distances, axis=1)
                            predictions[nan_mask] = 1 / (1 + min_distances)
                            
                        elif similarity_method == '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞':
                            from scipy.stats import pearsonr
                            correlations = []
                            for i in range(len(X_all_scaled[nan_mask])):
                                max_corr = 0
                                for j in range(len(X_train_scaled)):
                                    corr, _ = pearsonr(X_all_scaled[nan_mask][i], X_train_scaled[j])
                                    if not np.isnan(corr):
                                        max_corr = max(max_corr, abs(corr))
                                correlations.append(max_corr)
                            predictions[nan_mask] = correlations
                            
                        elif similarity_method == 'One-Class SVM':
                            from sklearn.svm import OneClassSVM
                            # –û–±—É—á–∞–µ–º One-Class SVM –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö COLL
                            ocsvm = OneClassSVM(kernel='rbf', gamma='scale', nu=0.1)
                            ocsvm.fit(X_train_scaled)
                            
                            # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏ (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –≥—Ä–∞–Ω–∏—Ü—ã —Ä–µ—à–µ–Ω–∏—è)
                            decision_scores = ocsvm.decision_function(X_all_scaled[nan_mask])
                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–∂–µ—Å—Ç—å (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
                            predictions[nan_mask] = (decision_scores - decision_scores.min()) / (decision_scores.max() - decision_scores.min() + 1e-8)
                            
                        elif similarity_method == '–ò–∑–æ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –ª–µ—Å':
                            from sklearn.ensemble import IsolationForest
                            # –û–±—É—á–∞–µ–º Isolation Forest –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö COLL
                            iso_forest = IsolationForest(contamination=0.1, random_state=42)
                            iso_forest.fit(X_train_scaled)
                            
                            # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏ (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –±–æ–ª–µ–µ –∞–Ω–æ–º–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞)
                            anomaly_scores = iso_forest.decision_function(X_all_scaled[nan_mask])
                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–∂–µ—Å—Ç—å (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
                            predictions[nan_mask] = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min() + 1e-8)
                        
                        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É Cov —Å–æ —Å—Ö–æ–∂–µ—Å—Ç—å—é
                        df['Cov'] = 0.0  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω—É–ª—è–º–∏
                        df.loc[nan_mask, 'Cov'] = predictions[nan_mask]
                        
                        # –°–æ–∑–¥–∞–µ–º COLL_advance –ø–æ –ø—Ä–∞–≤–∏–ª—É: 1 –µ—Å–ª–∏ COLL=1 –∏–ª–∏ Cov>0.98, –∏–Ω–∞—á–µ 0
                        coll_advance = np.zeros(len(df))
                        
                        # –°–ª—É—á–∞–π 1: COLL = 1
                        coll_1_mask = df['COLL'] == 1
                        coll_advance[coll_1_mask] = 1
                        
                        # –°–ª—É—á–∞–π 2: Cov > 0.98
                        cov_high_mask = df['Cov'] > 0.98
                        coll_advance[cov_high_mask] = 1
                        
                        df['COLL_advance'] = coll_advance
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        predicted_count = nan_mask.sum()
                        cov_high_count = (df['Cov'] > 0.98).sum()
                        coll_advance_1_count = (df['COLL_advance'] == 1).sum()
                        
                        st.success(f'üéØ –°–æ–∑–¥–∞–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ Cov –∏ COLL_advance!')
                        st.info(f'üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –º–µ—Ç–æ–¥: {similarity_method}')
                        st.info(f'üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:')
                        st.info(f'   ‚Ä¢ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ {predicted_count} –∑–Ω–∞—á–µ–Ω–∏–π —Å—Ö–æ–∂–µ—Å—Ç–∏ (Cov)')
                        st.info(f'   ‚Ä¢ {cov_high_count} —Ç–æ—á–µ–∫ —Å Cov > 0.98')
                        st.info(f'   ‚Ä¢ {coll_advance_1_count} —Ç–æ—á–µ–∫ —Å COLL_advance = 1')
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Ö–æ–∂–µ—Å—Ç–∏
                        st.subheader('üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏')
                        
                        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
                        similarity_data = {'Cov': df.loc[nan_mask, 'Cov']}
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                        if 'group_number' in df.columns:
                            similarity_data['–ì—Ä—É–ø–ø–∞'] = df.loc[nan_mask, 'group_number']
                        if 'well' in df.columns:
                            similarity_data['–°–∫–≤–∞–∂–∏–Ω–∞'] = df.loc[nan_mask, 'well']
                        if 'DEPTH' in df.columns:
                            similarity_data['–ì–ª—É–±–∏–Ω–∞'] = df.loc[nan_mask, 'DEPTH']
                        
                        similarity_stats = pd.DataFrame(similarity_data)
                        st.dataframe(similarity_stats.describe())
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10 —Å–∞–º—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ—á–µ–∫
                        st.subheader('üîç –¢–æ–ø-10 —Å–∞–º—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ—á–µ–∫')
                        top_similar = similarity_stats.nlargest(10, 'Cov')
                        st.dataframe(top_similar)
                        
                        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏
                        st.subheader('üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏')
                        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
                        
                        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
                        ax1.hist(df.loc[nan_mask, 'Cov'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
                        ax1.axvline(x=0.98, color='red', linestyle='--', label='–ü–æ—Ä–æ–≥ 0.98')
                        ax1.set_xlabel('Cov (—Å—Ö–æ–∂–µ—Å—Ç—å)')
                        ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫')
                        ax1.set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Cov ({similarity_method})')
                        ax1.legend()
                        ax1.grid(True, alpha=0.3)
                        
                        # Box plot –ø–æ –≥—Ä—É–ø–ø–∞–º –∏–ª–∏ —Å–∫–≤–∞–∂–∏–Ω–∞–º
                        if '–ì—Ä—É–ø–ø–∞' in similarity_stats.columns and len(similarity_stats['–ì—Ä—É–ø–ø–∞'].unique()) > 1:
                            similarity_stats.boxplot(column='Cov', by='–ì—Ä—É–ø–ø–∞', ax=ax2)
                            ax2.axhline(y=0.98, color='red', linestyle='--', alpha=0.7)
                            ax2.set_title('Cov –ø–æ –≥—Ä—É–ø–ø–∞–º')
                            ax2.set_xlabel('–ì—Ä—É–ø–ø–∞')
                            ax2.set_ylabel('Cov')
                        elif '–°–∫–≤–∞–∂–∏–Ω–∞' in similarity_stats.columns and len(similarity_stats['–°–∫–≤–∞–∂–∏–Ω–∞'].unique()) > 1:
                            similarity_stats.boxplot(column='Cov', by='–°–∫–≤–∞–∂–∏–Ω–∞', ax=ax2)
                            ax2.axhline(y=0.98, color='red', linestyle='--', alpha=0.7)
                            ax2.set_title('Cov –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º')
                            ax2.set_xlabel('–°–∫–≤–∞–∂–∏–Ω–∞')
                            ax2.set_ylabel('Cov')
                        else:
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–ª—É–±–∏–Ω–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                            if '–ì–ª—É–±–∏–Ω–∞' in similarity_stats.columns:
                                ax2.scatter(similarity_stats['–ì–ª—É–±–∏–Ω–∞'], similarity_stats['Cov'], alpha=0.6)
                                ax2.axhline(y=0.98, color='red', linestyle='--', alpha=0.7, label='–ü–æ—Ä–æ–≥ 0.98')
                                ax2.set_xlabel('–ì–ª—É–±–∏–Ω–∞')
                                ax2.set_ylabel('Cov')
                                ax2.set_title('Cov vs –ì–ª—É–±–∏–Ω–∞')
                                ax2.legend()
                                ax2.grid(True, alpha=0.3)
                            else:
                                ax2.text(0.5, 0.5, '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö\n–¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏', 
                                       ha='center', va='center', transform=ax2.transAxes)
                                ax2.set_title('–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                        st.subheader('üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ COLL –∏ COLL_advance')
                        
                        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
                        comparison_columns = ['COLL', 'Cov', 'COLL_advance']
                        if 'group_number' in df.columns:
                            comparison_columns.insert(0, 'group_number')
                        if 'well' in df.columns:
                            comparison_columns.insert(1, 'well')
                        if 'DEPTH' in df.columns:
                            comparison_columns.insert(-3, 'DEPTH')
                        
                        comparison_df = df[comparison_columns].copy()
                        st.dataframe(comparison_df.head(20))
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ COLL_advance
                        st.subheader('üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ COLL_advance')
                        coll_advance_stats = df['COLL_advance'].value_counts()
                        st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ COLL_advance:**")
                        st.write(coll_advance_stats)
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ—á–∫–∏ —Å Cov > 0.98
                        high_cov_points = df[df['Cov'] > 0.98]
                        if len(high_cov_points) > 0:
                            st.subheader('üéØ –¢–æ—á–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç—å—é (Cov > 0.98)')
                            high_cov_display = high_cov_points[comparison_columns].copy()
                            st.dataframe(high_cov_display)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        st.session_state.merged_data = df
                        st.success('üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ session_state.merged_data')
                        return
                    
                    st.info(f'üìä –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è "{target_column}" —Å–æ–¥–µ—Ä–∂–∏—Ç {unique_values} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {list(y_train.unique())}')
                    
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                    X_all = df[selected_features].fillna(df[selected_features].median())
                    y_all = df['COLL']
                    
                else:
                    # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                    X_train = df[selected_features].fillna(df[selected_features].median())
                    y_train = df[target_column]
                    X_all = X_train
                    y_all = y_train
                    train_mask = pd.Series([True] * len(df), index=df.index)
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                    unique_values = y_train.nunique()
                    if unique_values < 2:
                        st.error(f'‚ùå –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è "{target_column}" —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {y_train.iloc[0]}. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 —Ä–∞–∑–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.')
                        st.info('üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.')
                        return
                    
                    st.info(f'üìä –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è "{target_column}" —Å–æ–¥–µ—Ä–∂–∏—Ç {unique_values} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {list(y_train.unique())}')
                
                # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ–≤—ã–µ
                if not pd.api.types.is_numeric_dtype(y_train):
                    from sklearn.preprocessing import LabelEncoder
                    le = LabelEncoder()
                    y_train_encoded = le.fit_transform(y_train.astype(str))
                    y_original = y_train.copy()
                else:
                    y_train_encoded = y_train.fillna(y_train.median())
                    y_original = y_train.copy()
                
                # –ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ CatBoost –±–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
                if task_type == 'regression':
                    model = CatBoostRegressor(
                        iterations=n_estimators,
                        learning_rate=0.1,
                        depth=6,
                        random_seed=42,
                        verbose=False
                    )
                else:
                    model = CatBoostClassifier(
                        iterations=n_estimators,
                        learning_rate=0.1,
                        depth=6,
                        random_seed=42,
                        verbose=False
                    )
                
                # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
                model.fit(X_train, y_train_encoded)
                st.success(f'‚úÖ CatBoost –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!')
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
                predictions = model.predict(X_all)
                
                # –°–æ–∑–¥–∞–µ–º COLL_advance
                if target_column == 'COLL' and 'COLL' in df.columns:
                    # COLL_advance = COLL –≥–¥–µ –Ω–µ nan, –∏–Ω–∞—á–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    coll_advance = df['COLL'].copy()
                    nan_mask = df['COLL'].isna()
                    coll_advance[nan_mask] = predictions[nan_mask]
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    df['COLL_advance'] = coll_advance
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    predicted_count = nan_mask.sum()
                    st.success(f'üéØ –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ COLL_advance! –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ {predicted_count} –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è NaN –ø–æ–∑–∏—Ü–∏–π.')
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                    st.subheader('üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ COLL –∏ COLL_advance')
                    comparison_df = df[['group_number', 'well', 'COLL', 'COLL_advance']].copy()
                    if 'DEPTH' in df.columns:
                        comparison_df['DEPTH'] = df['DEPTH']
                    st.dataframe(comparison_df.head(20))
                
                # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏
                if not pd.api.types.is_numeric_dtype(y_original):
                    predictions_labels = le.inverse_transform(predictions.astype(int))
                else:
                    predictions_labels = predictions
                
                # –ú–µ—Ç—Ä–∏–∫–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                if task_type == 'regression':
                    train_predictions = predictions[train_mask] if target_column == 'COLL' else predictions
                    r2 = r2_score(y_train_encoded, train_predictions)
                    st.success(f'‚úÖ CatBoost –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞! R¬≤ = {r2:.3f} (–Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö)')
                else:
                    train_predictions = predictions[train_mask] if target_column == 'COLL' else predictions
                    acc = accuracy_score(y_train_encoded, train_predictions)
                    st.success(f'‚úÖ CatBoost –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞! Accuracy = {acc:.3f} (–Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö)')
                
                # –ì—Ä–∞—Ñ–∏–∫
                fig, ax = plt.subplots(figsize=(8, 6))
                if task_type == 'regression':
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ
                    train_predictions = predictions[train_mask] if target_column == 'COLL' else predictions
                    ax.scatter(y_train_encoded, train_predictions, alpha=0.6, color='blue', label='–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ')
                    ax.plot([y_train_encoded.min(), y_train_encoded.max()], [y_train_encoded.min(), y_train_encoded.max()], 'r--', label='–ò–¥–µ–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è')
                    ax.set_xlabel('–§–∞–∫—Ç')
                    ax.set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ')
                    ax.set_title('CatBoost: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs –§–∞–∫—Ç (–æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ)')
                    ax.legend()
                else:
                    # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                    prediction_counts = pd.Series(predictions_labels).value_counts().sort_index()
                    ax.bar(range(len(prediction_counts)), prediction_counts.values, color='skyblue', alpha=0.7)
                    ax.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã')
                    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤')
                    ax.set_title('CatBoost: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π')
                    ax.set_xticks(range(len(prediction_counts)))
                    ax.set_xticklabels(prediction_counts.index, rotation=45)
                
                st.pyplot(fig)
                
                # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
                results_df = df.copy()
                results_df['prediction'] = predictions_labels
                results_df['prediction_numeric'] = predictions
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                display_columns = [target_column, 'prediction']
                if 'group_number' in results_df.columns:
                    display_columns.insert(0, 'group_number')
                if 'well' in results_df.columns:
                    display_columns.insert(1, 'well')
                if 'DEPTH' in results_df.columns:
                    display_columns.insert(-2, 'DEPTH')
                if 'Cov' in results_df.columns:
                    display_columns.append('Cov')
                if 'COLL_advance' in results_df.columns:
                    display_columns.append('COLL_advance')
                
                st.dataframe(results_df[display_columns].head(20))
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º
                st.subheader('üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º')
                prediction_stats = results_df.groupby('prediction').agg({
                    target_column: 'count',
                    **{col: 'mean' for col in selected_features if col in results_df.columns}
                }).round(3)
                st.dataframe(prediction_stats)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ session_state
                st.session_state.merged_data = results_df
                st.success('üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ session_state.merged_data')
                
            except Exception as e:
                st.error(f'‚ùå –û—à–∏–±–∫–∞: {str(e)}')
