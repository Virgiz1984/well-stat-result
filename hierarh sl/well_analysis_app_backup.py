import streamlit as st

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ —Å–∫–≤–∞–∂–∏–Ω: LAS + –ò—Å–ø—ã—Ç–∞–Ω–∏—è", layout="wide")

import io
import os
import tempfile
import base64
from datetime import datetime
from typing import List, Tuple, Optional, Dict, Any
import zipfile

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.compose import ColumnTransformer
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
from sklearn.metrics import pairwise_distances
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# –ü–ª–∞–≤–Ω–∞—è –∫–∞—Ä—Ç–∞: RBF-–∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è + –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏
from scipy.interpolate import Rbf, griddata
from scipy.spatial import Delaunay
import plotly.graph_objects as go

# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å LAS —Ñ–∞–π–ª–∞–º–∏
try:
    import lasio
    LASIO_AVAILABLE = True
except ImportError:
    LASIO_AVAILABLE = False
    st.warning("lasio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install lasio")

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è –∞–≥–ª–æ–º–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞
try:
    from agglomerative_boosting import create_boosting_interface
    BOOSTING_AVAILABLE = True
except ImportError:
    BOOSTING_AVAILABLE = False

def generate_clustering_report(df, sel_num, sel_cat, standardize, metric, linkage_method, id_col):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á—ë—Ç–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
    
    # –°–æ–∑–¥–∞—ë–º HTML —à–∞–±–ª–æ–Ω
    html_template = """
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>–û—Ç—á—ë—Ç –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            h1 {{ color: #2E86AB; }}
            h2 {{ color: #A23B72; }}
            h3 {{ color: #F18F01; }}
            .info-box {{ background-color: #f0f8ff; padding: 10px; border-left: 4px solid #2E86AB; margin: 10px 0; }}
            .warning-box {{ background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin: 10px 0; }}
            .success-box {{ background-color: #d4edda; padding: 10px; border-left: 4px solid #28a745; margin: 10px 0; }}
            table {{ border-collapse: collapse; width: 100%; margin: 10px 0; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            .metric {{ font-weight: bold; color: #2E86AB; }}
            .center {{ text-align: center; }}
            img {{ max-width: 100%; height: auto; margin: 10px 0; }}
        </style>
    </head>
    <body>
        <h1>üìä –û—Ç—á—ë—Ç –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤</h1>
        
        <div class="info-box">
            <strong>üìÖ –î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:</strong> {date}<br>
            <strong>üîç –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:</strong> COLL == 1 –∏ TEST –Ω–µ –ø—É—Å—Ç–æ–π<br>
            <strong>üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤:</strong> {count}
        </div>
        
        <h2>‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞</h2>
        <table>
            <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–ó–Ω–∞—á–µ–Ω–∏–µ</th></tr>
            <tr><td>–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</td><td>{numeric_features}</td></tr>
            <tr><td>–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</td><td>{categorical_features}</td></tr>
            <tr><td>–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è</td><td>{standardize}</td></tr>
            <tr><td>–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è</td><td>{metric}</td></tr>
            <tr><td>–ú–µ—Ç–æ–¥ —Å–≤—è–∑—ã–≤–∞–Ω–∏—è</td><td>{linkage_method}</td></tr>
        </table>
        
        <h2>üìã –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞</h2>
        {data_table}
        
        <h2>üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏</h2>
        {clustering_results}
        
        <h2>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h2>
        {statistics}
        
        <div class="success-box">
            <strong>‚úÖ –û—Ç—á—ë—Ç —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω!</strong><br>
            –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {count} –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ —Å COLL=1 –∏ –Ω–µ –ø—É—Å—Ç—ã–º TEST.
        </div>
    </body>
    </html>
    """
    
    try:
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df_clean = df.dropna(subset=[id_col]).reset_index(drop=True)
        
        if len(df_clean) == 0:
            return html_template.format(
                date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                count=0,
                numeric_features=", ".join(sel_num) if sel_num else "–ù–µ—Ç",
                categorical_features=", ".join(sel_cat) if sel_cat else "–ù–µ—Ç",
                standardize="–î–∞" if standardize else "–ù–µ—Ç",
                metric=metric,
                linkage_method=linkage_method,
                data_table="<p>–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞</p>",
                clustering_results="<p>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏</p>",
                statistics="<p>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞</p>"
            )
        
        # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É –¥–∞–Ω–Ω—ã—Ö
        display_cols = ['group_number', 'well', 'top', 'bottom', 'h', 'COLL', 'TEST']
        available_display_cols = [col for col in display_cols if col in df_clean.columns]
        data_table_html = df_clean[available_display_cols].to_html(index=False, classes="table")
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–æ–ª—â–∏–Ω–µ
        h_mean = f"{df_clean['h'].mean():.2f}" if 'h' in df_clean.columns else 'N/A'
        h_min = f"{df_clean['h'].min():.2f}" if 'h' in df_clean.columns else 'N/A'
        h_max = f"{df_clean['h'].max():.2f}" if 'h' in df_clean.columns else 'N/A'
        
        stats_html = f"""
        <table>
            <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>–ó–Ω–∞—á–µ–Ω–∏–µ</th></tr>
            <tr><td>–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤</td><td class="metric">{len(df_clean)}</td></tr>
            <tr><td>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫–≤–∞–∂–∏–Ω</td><td class="metric">{df_clean['well'].nunique() if 'well' in df_clean.columns else 'N/A'}</td></tr>
            <tr><td>–°—Ä–µ–¥–Ω—è—è —Ç–æ–ª—â–∏–Ω–∞, –º</td><td class="metric">{h_mean}</td></tr>
            <tr><td>–ú–∏–Ω. —Ç–æ–ª—â–∏–Ω–∞, –º</td><td class="metric">{h_min}</td></tr>
            <tr><td>–ú–∞–∫—Å. —Ç–æ–ª—â–∏–Ω–∞, –º</td><td class="metric">{h_max}</td></tr>
        </table>
        """
        
        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)
        clustering_results = ""
        if len(sel_num) + len(sel_cat) > 0 and len(df_clean) > 1:
            try:
                # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
                X, labels = compute_features(df_clean, id_col, sel_num, sel_cat, standardize)
                
                if len(X) > 1:
                    # –°–æ–∑–¥–∞—ë–º –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—É
                    metric_for_linkage = "euclidean" if linkage_method == "ward" else metric
                    Z = linkage(X, method=linkage_method, metric=metric_for_linkage)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—É –≤ base64
                    fig, ax = plt.subplots(figsize=(12, 8), dpi=150)
                    dendrogram(Z, labels=labels, leaf_rotation=90, leaf_font_size=10, ax=ax)
                    ax.set_title("–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
                    ax.set_ylabel("–î–∏—Å—Ç–∞–Ω—Ü–∏—è")
                    fig.tight_layout()
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
                    buffer = io.BytesIO()
                    fig.savefig(buffer, format='png', bbox_inches='tight', dpi=150)
                    buffer.seek(0)
                    image_base64 = base64.b64encode(buffer.getvalue()).decode()
                    plt.close(fig)
                    
                    clustering_results = f"""
                    <h3>–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞</h3>
                    <img src="data:image/png;base64,{image_base64}" alt="–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞">
                    
                    <h3>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏</h3>
                    <table>
                        <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–ó–Ω–∞—á–µ–Ω–∏–µ</th></tr>
                        <tr><td>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤</td><td class="metric">{len(X)}</td></tr>
                        <tr><td>–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</td><td class="metric">{X.shape[1]}</td></tr>
                        <tr><td>–ú–µ—Ç–æ–¥ —Å–≤—è–∑—ã–≤–∞–Ω–∏—è</td><td>{linkage_method}</td></tr>
                        <tr><td>–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è</td><td>{metric}</td></tr>
                    </table>
                    """
                else:
                    clustering_results = "<p>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—ã</p>"
                    
            except Exception as e:
                clustering_results = f"<div class='warning-box'>–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {str(e)}</div>"
        else:
            clustering_results = "<p>–ù–µ –≤—ã–±—Ä–∞–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏</p>"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π HTML
        return html_template.format(
            date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            count=len(df_clean),
            numeric_features=", ".join(sel_num) if sel_num else "–ù–µ—Ç",
            categorical_features=", ".join(sel_cat) if sel_cat else "–ù–µ—Ç",
            standardize="–î–∞" if standardize else "–ù–µ—Ç",
            metric=metric,
            linkage_method=linkage_method,
            data_table=data_table_html,
            clustering_results=clustering_results,
            statistics=stats_html
        )
        
    except Exception as e:
        error_html = f"""
        <div class="warning-box">
            <strong>‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞:</strong><br>
            {str(e)}
        </div>
        """
        return html_template.format(
            date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            count=0,
            numeric_features="–û—à–∏–±–∫–∞",
            categorical_features="–û—à–∏–±–∫–∞",
            standardize="–û—à–∏–±–∫–∞",
            metric="–û—à–∏–±–∫–∞",
            linkage_method="–û—à–∏–±–∫–∞",
            data_table="<p>–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö</p>",
            clustering_results=error_html,
            statistics="<p>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞</p>"
        )
    # st.warning("–ú–æ–¥—É–ª—å –∞–≥–ª–æ–º–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LAS —Ñ–∞–π–ª–∞–º–∏
def read_las_file(file_content: bytes, filename: str) -> pd.DataFrame:
    """–ß–∏—Ç–∞–µ—Ç LAS —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame"""
    if not LASIO_AVAILABLE:
        raise ImportError("lasio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    with tempfile.NamedTemporaryFile(suffix='.las', delete=False) as tmp_file:
        tmp_file.write(file_content)
        tmp_file_path = tmp_file.name
    
    try:
        # –ß–∏—Ç–∞–µ–º LAS —Ñ–∞–π–ª
        las = lasio.read(tmp_file_path)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        df = las.df()
        df.reset_index(inplace=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∫–≤–∞–∂–∏–Ω–µ
        well_name = getattr(las.well, 'WELL', {}).get('VALUE', filename.split('.')[0])
        df['well'] = str(well_name)
        
        return df
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(tmp_file_path)

def process_las_files(uploaded_files) -> pd.DataFrame:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ LAS —Ñ–∞–π–ª—ã"""
    all_data = []
    
    for uploaded_file in uploaded_files:
        try:
            file_content = uploaded_file.read()
            df = read_las_file(file_content, uploaded_file.name)
            all_data.append(df)
            st.success(f"‚úÖ {uploaded_file.name}: {len(df)} —Ç–æ—á–µ–∫")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {uploaded_file.name}: {str(e)}")
    
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        st.success(f"üìä –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(combined_df)} —Ç–æ—á–µ–∫ –∏–∑ {len(all_data)} —Ñ–∞–π–ª–æ–≤")
        return combined_df
    else:
        return pd.DataFrame()

def thick_to_dots(las: pd.DataFrame, core: pd.DataFrame, list_las_to_core: List[str]) -> pd.DataFrame:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ LAS –∏ —Ç–∞–±–ª–∏—Ü—ã –∏—Å–ø—ã—Ç–∞–Ω–∏–π –ø–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º
    
    Args:
        las: DataFrame —Å LAS –¥–∞–Ω–Ω—ã–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'well', 'DEPTH')
        core: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –∏—Å–ø—ã—Ç–∞–Ω–∏–π (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'well', 'top', 'bottom')
        list_las_to_core: —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ core –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –≤ las
    
    Returns:
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame
    """
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å–∫–≤–∞–∂–∏–Ω –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø
    las = las.copy()
    core = core.copy()
    las['well'] = las['well'].astype(str)
    core['well'] = core['well'].astype(str)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º core —Ç–æ–ª—å–∫–æ –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ las
    core_filtered = core[core["well"].isin(las["well"].unique())].copy()
    
    if core_filtered.empty:
        st.warning("–ù–µ—Ç –æ–±—â–∏—Ö —Å–∫–≤–∞–∂–∏–Ω –º–µ–∂–¥—É LAS –¥–∞–Ω–Ω—ã–º–∏ –∏ —Ç–∞–±–ª–∏—Ü–µ–π –∏—Å–ø—ã—Ç–∞–Ω–∏–π")
        return las
    
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    result_list = []
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º
    for well_name, core_part in core_filtered.groupby("well"):
        las_part = las[las["well"] == well_name].copy()
        
        # –ú–µ—Ä–∂–∏–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–≤–∞–ª
        for _, row in core_part.iterrows():
            mask = (las_part["DEPTH"] >= row["top"]) & (las_part["DEPTH"] < row["bottom"])
            for col in list_las_to_core:
                if col in row:
                    las_part.loc[mask, col] = row[col]
        
        result_list.append(las_part)
    
    return pd.concat(result_list, ignore_index=True) if result_list else pd.DataFrame()

def calculate_group_number(df: pd.DataFrame, coll_column: str = 'coll') -> pd.DataFrame:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç group_number –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö coll –∏ well
    """
    df = df.copy()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    if coll_column not in df.columns:
        st.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ '{coll_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. group_number –Ω–µ –±—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.")
        return df
    
    if 'well' not in df.columns:
        st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'well' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. group_number –Ω–µ –±—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.")
        return df
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    df['well'] = df['well'].astype(str)
    df[coll_column] = df[coll_column].astype(str)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–≤–∞–∂–∏–Ω–µ –∏ –≥–ª—É–±–∏–Ω–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
    if 'DEPTH' in df.columns:
        df = df.sort_values(['well', 'DEPTH']).reset_index(drop=True)
    else:
        df = df.sort_values(['well']).reset_index(drop=True)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—ã–µ –≥—Ä—É–ø–ø—ã: –∏–∑–º–µ–Ω–µ–Ω–∏–µ coll –∏–ª–∏ well
    new_group = (df[coll_column] != df[coll_column].shift(1)) | (df['well'] != df['well'].shift(1))
    
    # –ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ –Ω—É–º–µ—Ä—É–µ–º –≥—Ä—É–ø–ø—ã –ø–æ –≤—Å–µ–º—É DataFrame
    df['group_number'] = new_group.cumsum()
    
    st.success(f"‚úÖ group_number —Ä–∞—Å—Å—á–∏—Ç–∞–Ω: {df['group_number'].nunique()} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä—É–ø–ø")
    
    return df

def aggregate_to_collectors(df: pd.DataFrame, group_by_column: str = None) -> pd.DataFrame:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ø–æ—Ç–æ—á–µ—á–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –≤ —Ç–∞–±–ª–∏—Ü—É –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤
    
    Args:
        df: DataFrame —Å –ø–æ—Ç–æ—á–µ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        group_by_column: –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (–∞–Ω–∞–ª–æ–≥ 'coll')
    """
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å–∫–≤–∞–∂–∏–Ω –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø
    df = df.copy()
    if 'well' in df.columns:
        df['well'] = df['well'].astype(str)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º group_number –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if 'group_number' not in df.columns:
        st.info("üîÑ –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º group_number...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        if group_by_column and group_by_column in df.columns:
            coll_col = group_by_column
        elif (st.session_state.selected_coll_column and 
              st.session_state.selected_coll_column in df.columns):
            coll_col = st.session_state.selected_coll_column
        else:
            # Fallback: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            if 'coll' in df.columns:
                coll_col = 'coll'
            elif 'COLL' in df.columns:
                coll_col = 'COLL'
            elif '–∫–æ–ª–ª–µ–∫—Ç–æ—Ä' in df.columns:
                coll_col = '–∫–æ–ª–ª–µ–∫—Ç–æ—Ä'
            else:
                # –ò—â–µ–º –ø–µ—Ä–≤—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–æ–ª–æ–Ω–∫—É
                available_cols = [col for col in df.columns if col not in ['well', 'DEPTH', 'group_number']]
                coll_col = available_cols[0] if available_cols else 'coll'
        
        df = calculate_group_number(df, coll_col)
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è h < 0.4
    if 'h' in df.columns:
        initial_count = len(df)
        df = df[df['h'] >= 0.4]
        filtered_count = len(df)
        if initial_count != filtered_count:
            st.info(f"üîç –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {initial_count - filtered_count} —Ç–æ—á–µ–∫ —Å h < 0.4. –û—Å—Ç–∞–ª–æ—Å—å {filtered_count} —Ç–æ—á–µ–∫.")
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Å–µ LAS –∫—Ä–∏–≤—ã–µ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–Ω–æ –≤–∫–ª—é—á–∞–µ–º COLL)
    service_columns = ['well', 'DEPTH', 'group_number', 'top', 'bottom', 'h', 'coll', '–∫–æ–ª–ª–µ–∫—Ç–æ—Ä']
    
    # –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª—É–∂–µ–±–Ω—ã–º–∏ - —ç—Ç–æ –∏ –µ—Å—Ç—å LAS –∫—Ä–∏–≤—ã–µ (–≤–∫–ª—é—á–∞—è COLL)
    available_las_curves = [c for c in df.columns 
                           if pd.api.types.is_numeric_dtype(df[c]) and c not in service_columns]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º
    if hasattr(st.session_state, 'selected_las_curves') and st.session_state.selected_las_curves:
        selected_las_curves = st.session_state.selected_las_curves
    else:
        selected_las_curves = available_las_curves
    
    # –í—Å–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ LAS –∫—Ä–∏–≤—ã–µ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
    all_potential_mean_columns = selected_las_curves
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
    mean_columns = []
    for col in all_potential_mean_columns:
        if col in df.columns:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ —á–∏—Å–ª–æ–≤–∞—è
            if pd.api.types.is_numeric_dtype(df[col]):
                mean_columns.append(col)
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø
                try:
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
                    converted_col = pd.to_numeric(df[col], errors='coerce')
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    if not converted_col.isna().all():
                        # –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É –Ω–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—É—é
                        df[col] = converted_col
                        mean_columns.append(col)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É '{col}' –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø: {str(e)}")
                    pass  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫—É, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö LAS –∫—Ä–∏–≤—ã—Ö
    if available_las_curves:
        st.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(available_las_curves)} LAS –∫—Ä–∏–≤—ã—Ö –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
        if len(available_las_curves) <= 10:
            st.info(f"üìä –ö—Ä–∏–≤—ã–µ: {', '.join(available_las_curves)}")
        else:
            st.info(f"üìä –ö—Ä–∏–≤—ã–µ: {', '.join(available_las_curves[:10])}... (–∏ –µ—â–µ {len(available_las_curves)-10})")
        
        if mean_columns:
            st.success(f"‚úÖ {len(mean_columns)} –∫—Ä–∏–≤—ã—Ö –≤—ã–±—Ä–∞–Ω–æ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è")
        else:
            st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö LAS –∫—Ä–∏–≤—ã—Ö –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è")
    else:
        st.warning("‚ö†Ô∏è LAS –∫—Ä–∏–≤—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    if st.checkbox("üîç –ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é", help="–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–ª–æ–Ω–æ–∫"):
        st.write("**–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö:**")
        for col in df.columns:
            dtype = df[col].dtype
            st.write(f"- {col}: {dtype}")
        
        st.write("**–ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏:**")
        st.write(f"- –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (mean): {mean_columns}")
        st.write(f"- –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ (sum): {count_columns}")
        st.write(f"- –ú–æ–¥–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {mode_columns}")
        st.write(f"- Min/Max: {min_max_columns}")
    
    # –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–±—ã—á–Ω–æ —Å—á–µ—Ç—á–∏–∫–∏) - —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ
    potential_count_columns = ['COLL_poro_type', 'COLL_frac_type', 'COLL_mix_type', 'COLL']
    count_columns = [c for c in potential_count_columns if c in df.columns and pd.api.types.is_numeric_dtype(df[c])]
    
    # –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ)
    if hasattr(st.session_state, 'selected_categorical') and st.session_state.selected_categorical:
        selected_categorical = st.session_state.selected_categorical
    else:
        potential_mode_columns = ['well', 'TYPE', '–ö–ª–∞—Å—Ç–µ—Ä—ã –ì–ò–°', '–õ–∏—Ç–æ–ª–æ–≥–∏—è –ø–æ –ì–ò–°', 'TEST', 'BF', 'fluid type', 'coll_type', 'coll', 'COLL']
        selected_categorical = [c for c in potential_mode_columns if c in df.columns]
    
    mode_columns = [c for c in selected_categorical if c in df.columns]
    
    # –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è min/max (–æ–±—ã—á–Ω–æ –≥–ª—É–±–∏–Ω—ã) - —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ
    potential_min_max_columns = ['DEPTH']
    min_max_columns = [c for c in potential_min_max_columns if c in df.columns and pd.api.types.is_numeric_dtype(df[c])]
    
    def most_frequent(s):
        s = s.dropna()
        return s.value_counts().idxmax() if not s.empty else np.nan
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
    agg_dict = {}
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
    for c in mean_columns:
        if c in df.columns:
            agg_dict[c] = 'mean'
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
    for c in count_columns:
        if c in df.columns:
            agg_dict[c] = 'sum'
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
    for c in mode_columns:
        if c in df.columns:
            agg_dict[c] = most_frequent
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è min/max
    for c in min_max_columns:
        if c in df.columns:
            agg_dict[c] = ['min', 'max']
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ group_number
    if 'group_number' not in df.columns:
        st.error("–ö–æ–ª–æ–Ω–∫–∞ 'group_number' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        return df
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º group_number –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø
    df['group_number'] = df['group_number'].astype(str)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ agg_dict –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —á–∏—Å–ª–æ–≤—ã–µ
    final_agg_dict = {}
    for col, agg_func in agg_dict.items():
        if col in df.columns:
            if agg_func == 'mean':
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è mean
                if pd.api.types.is_numeric_dtype(df[col]):
                    final_agg_dict[col] = agg_func
                else:
                    st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫—É '{col}' –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è - –Ω–µ —á–∏—Å–ª–æ–≤–∞—è")
            elif agg_func == 'sum':
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è sum
                if pd.api.types.is_numeric_dtype(df[col]):
                    final_agg_dict[col] = agg_func
                else:
                    st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫—É '{col}' –¥–ª—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è - –Ω–µ —á–∏—Å–ª–æ–≤–∞—è")
            elif agg_func == ['min', 'max']:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è min/max
                if pd.api.types.is_numeric_dtype(df[col]):
                    final_agg_dict[col] = agg_func
                else:
                    st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫—É '{col}' –¥–ª—è min/max - –Ω–µ —á–∏—Å–ª–æ–≤–∞—è")
            else:
                # –î–ª—è most_frequent –∏ –¥—Ä—É–≥–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π
                final_agg_dict[col] = agg_func
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
    if not final_agg_dict:
        st.error("‚ùå –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
        return df
    
    try:
        result = df.groupby('group_number', dropna=False).agg(final_agg_dict).reset_index()
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {str(e)}")
        st.error("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö")
        return df
    
    # –ü–ª–æ—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –∑–∞–º–µ–Ω–æ–π DEPTH_min/DEPTH_max
    new_columns = []
    for col in result.columns:
        if isinstance(col, tuple):
            if col[0] == 'DEPTH' and col[1] == 'min':
                new_columns.append('top')
            elif col[0] == 'DEPTH' and col[1] == 'max':
                new_columns.append('bottom')
            else:
                new_columns.append(col[0])
        else:
            new_columns.append(col)
    
    result.columns = new_columns
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—â–∏–Ω—É
    if 'top' in result.columns and 'bottom' in result.columns:
        result['h'] = result['bottom'] - result['top']
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–ª–ª–µ–∫—Ç–æ—Ä—ã
    if 'coll_type' in result.columns and 'h' in result.columns:
        result = result[(result['h'] > 0.3) & (result['coll_type'] != '–Ω–µ–∫–æ–ª–ª–µ–∫—Ç–æ—Ä')]
    
    return result

# –§—É–Ω–∫—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)
def get_numeric_and_categorical_columns(df: pd.DataFrame, id_col: str) -> Tuple[List[str], List[str]]:
    numeric_cols, categorical_cols = [], []
    for c in df.columns:
        if c == id_col:
            continue
        if pd.api.types.is_numeric_dtype(df[c]) and not pd.api.types.is_bool_dtype(df[c]):
            numeric_cols.append(c)
        else:
            categorical_cols.append(c)
    return numeric_cols, categorical_cols

def make_preprocessor(numeric_cols: List[str], categorical_cols: List[str], standardize: bool) -> ColumnTransformer:
    numeric_steps = [("imputer", SimpleImputer(strategy="median"))]
    if standardize:
        numeric_steps.append(("scaler", StandardScaler()))
    numeric_pipeline = Pipeline(steps=numeric_steps)
    
    try:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)
    
    categorical_pipeline = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("ohe", ohe),
    ])
    
    try:
        return ColumnTransformer(
            transformers=[("num", numeric_pipeline, numeric_cols),
                          ("cat", categorical_pipeline, categorical_cols)],
            remainder="drop",
            verbose_feature_names_out=False,
        )
    except TypeError:
        return ColumnTransformer(
            transformers=[("num", numeric_pipeline, numeric_cols),
                          ("cat", categorical_pipeline, categorical_cols)],
            remainder="drop",
        )

def ensure_unique_labels(labels: List[str]) -> List[str]:
    seen, out = {}, []
    for lbl in labels:
        seen[lbl] = seen.get(lbl, 0) + 1
        out.append(lbl if seen[lbl] == 1 else f"{lbl}#{seen[lbl]}")
    return out

@st.cache_data(show_spinner=False)
def compute_features(df: pd.DataFrame, id_col: str, selected_numeric: List[str],
                     selected_categorical: List[str], standardize: bool) -> Tuple[np.ndarray, List[str]]:
    preprocessor = make_preprocessor(selected_numeric, selected_categorical, standardize)
    X = preprocessor.fit_transform(df[selected_numeric + selected_categorical])
    labels = ensure_unique_labels(df[id_col].astype(str).tolist())
    return X, labels

def compute_top_k_similar(X: np.ndarray, labels: List[str], target_label: str, metric: str, k: int):
    idx = {l: i for i, l in enumerate(labels)}
    if target_label not in idx:
        raise ValueError("–í—ã–±—Ä–∞–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    ti = idx[target_label]
    d = pairwise_distances(X, X[ti].reshape(1, -1), metric=metric).ravel()
    order = [i for i in np.argsort(d) if i != ti][:k]
    return [labels[i] for i in order], d[order]

def plot_dendrogram_subset(X_subset: np.ndarray, labels_subset: List[str],
                           linkage_method: str, metric: str,
                           target_display_label: str):
    metric_for_linkage = "euclidean" if linkage_method == "ward" else metric
    Z = linkage(X_subset, method=linkage_method, metric=metric_for_linkage)
    fig, ax = plt.subplots(figsize=(9, 7), dpi=150)
    dendrogram(Z, labels=labels_subset, leaf_rotation=90, leaf_font_size=12, ax=ax)
    ax.set_title("–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ (—Ü–µ–ª–µ–≤–æ–π + 10 –ø–æ—Ö–æ–∂–∏—Ö)")
    ax.set_ylabel("–î–∏—Å—Ç–∞–Ω—Ü–∏—è")
    for tick in ax.get_xmajorticklabels():
        if tick.get_text() == target_display_label:
            tick.set_color("crimson")
            tick.set_fontweight("bold")
        else:
            tick.set_color("black")
    fig.tight_layout()
    return fig

def format_display_label(row: pd.Series, id_value: str) -> str:
    parts = [str(id_value)]
    if "well" in row.index and pd.notna(row["well"]) and str(row["well"]).strip() != "":
        parts.append(str(row["well"]))
    if "Q" in row.index and pd.notna(row["Q"]):
        try:
            q = float(row["Q"])
            parts.append(f"Q={q:.3g}")
        except Exception:
            parts.append(f"Q={row['Q']}")
    return " | ".join(parts)

def make_display_labels(df: pd.DataFrame, indices: List[int], id_col: str) -> List[str]:
    out = []
    for i in indices:
        orig_id = str(df.iloc[i][id_col])
        out.append(format_display_label(df.iloc[i], orig_id))
    return out

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.title("üî¨ –ê–Ω–∞–ª–∏–∑ —Å–∫–≤–∞–∂–∏–Ω: LAS + –ò—Å–ø—ã—Ç–∞–Ω–∏—è")
st.caption("–ó–∞–≥—Ä—É–∑–∏—Ç–µ LAS —Ñ–∞–π–ª—ã –∏ —Ç–∞–±–ª–∏—Ü—É –∏—Å–ø—ã—Ç–∞–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session state
if 'las_data' not in st.session_state:
    st.session_state.las_data = pd.DataFrame()
if 'core_data' not in st.session_state:
    st.session_state.core_data = pd.DataFrame()
if 'merged_data' not in st.session_state:
    st.session_state.merged_data = pd.DataFrame()
if 'aggregated_data' not in st.session_state:
    st.session_state.aggregated_data = pd.DataFrame()
if 'selected_coll_column' not in st.session_state:
    st.session_state.selected_coll_column = None

# –°–æ–∑–¥–∞–µ–º —Ç–∞–±—ã
tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", "üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ", "üöÄ –ë—É—Å—Ç–∏–Ω–≥", "üìä –ê–≥—Ä–µ–≥–∞—Ü–∏—è", "üìÑ –û—Ç—á—ë—Ç—ã"])

with tab1:
    st.header("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    # –ö–Ω–æ–ø–∫–∞ –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ", help="–£–¥–∞–ª–∏—Ç—å –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"):
        st.session_state.las_data = pd.DataFrame()
        st.session_state.core_data = pd.DataFrame()
        st.session_state.merged_data = pd.DataFrame()
        st.session_state.aggregated_data = pd.DataFrame()
        st.session_state.selected_coll_column = None
        st.success("‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã")
        st.rerun()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1. LAS —Ñ–∞–π–ª—ã")
        if not LASIO_AVAILABLE:
            st.error("‚ö†Ô∏è lasio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install lasio")
        else:
            uploaded_las_files = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ LAS —Ñ–∞–π–ª—ã",
                type=['las'],
                accept_multiple_files=True,
                help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ LAS —Ñ–∞–π–ª–æ–≤"
            )
            
            if uploaded_las_files:
                if st.button("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å LAS —Ñ–∞–π–ª—ã"):
                    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ LAS —Ñ–∞–π–ª–æ–≤..."):
                        st.session_state.las_data = process_las_files(uploaded_las_files)
                
                if not st.session_state.las_data.empty:
                    st.success(f"‚úÖ LAS –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(st.session_state.las_data)} —Ç–æ—á–µ–∫")
                    st.dataframe(st.session_state.las_data.head(), use_container_width=True)
                    
                    # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ LAS –¥–∞–Ω–Ω—ã—Ö
                    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å LAS –¥–∞–Ω–Ω—ã–µ", help="–£–¥–∞–ª–∏—Ç—å –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ LAS –¥–∞–Ω–Ω—ã–µ"):
                        st.session_state.las_data = pd.DataFrame()
                        st.session_state.merged_data = pd.DataFrame()
                        st.session_state.aggregated_data = pd.DataFrame()
                        st.success("‚úÖ LAS –¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã")
                        st.rerun()
    
    with col2:
        st.subheader("2. –¢–∞–±–ª–∏—Ü–∞ –∏—Å–ø—ã—Ç–∞–Ω–∏–π")
        uploaded_core_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –∏—Å–ø—ã—Ç–∞–Ω–∏—è–º–∏",
            type=['xlsx', 'xls', 'csv'],
            help="Excel –∏–ª–∏ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –∏—Å–ø—ã—Ç–∞–Ω–∏–π"
        )
        
        if uploaded_core_file:
            if st.button("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É –∏—Å–ø—ã—Ç–∞–Ω–∏–π"):
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã –∏—Å–ø—ã—Ç–∞–Ω–∏–π..."):
                    try:
                        if uploaded_core_file.name.endswith(('.xlsx', '.xls')):
                            st.session_state.core_data = pd.read_excel(uploaded_core_file, engine="openpyxl")
                        else:
                            st.session_state.core_data = pd.read_csv(uploaded_core_file)
                        
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å–∫–≤–∞–∂–∏–Ω –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø
                        if 'well' in st.session_state.core_data.columns:
                            st.session_state.core_data['well'] = st.session_state.core_data['well'].astype(str)
                        
                        st.success(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ –∏—Å–ø—ã—Ç–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(st.session_state.core_data)} –∑–∞–ø–∏—Å–µ–π")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {str(e)}")
            
            if not st.session_state.core_data.empty:
                st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(st.session_state.core_data)} –∑–∞–ø–∏—Å–µ–π")
                st.dataframe(st.session_state.core_data.head(), use_container_width=True)
                
                # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø—ã—Ç–∞–Ω–∏–π
                if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–π", help="–£–¥–∞–ª–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–π"):
                    st.session_state.core_data = pd.DataFrame()
                    st.session_state.merged_data = pd.DataFrame()
                    st.session_state.aggregated_data = pd.DataFrame()
                    st.success("‚úÖ –î–∞–Ω–Ω—ã–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–π –æ—á–∏—â–µ–Ω—ã")
                    st.rerun()

with tab2:
    st.header("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    
    if st.session_state.las_data.empty or st.session_state.core_data.empty:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ LAS —Ñ–∞–π–ª—ã –∏ —Ç–∞–±–ª–∏—Ü—É –∏—Å–ø—ã—Ç–∞–Ω–∏–π")
    else:
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        
        # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞
        available_columns = [col for col in st.session_state.core_data.columns 
                           if col not in ['well', 'top', 'bottom']]
        
        selected_columns = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –∏—Å–ø—ã—Ç–∞–Ω–∏–π –≤ LAS –¥–∞–Ω–Ω—ã–µ:",
            options=available_columns,
            default=available_columns[:5] if len(available_columns) > 5 else available_columns
        )
        
        if st.button("üîó –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
            with st.spinner("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö..."):
                try:
                    st.session_state.merged_data = thick_to_dots(
                        st.session_state.las_data,
                        st.session_state.core_data,
                        selected_columns
                    )
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã: {len(st.session_state.merged_data)} —Ç–æ—á–µ–∫")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏: {str(e)}")
        
        if not st.session_state.merged_data.empty:
            st.subheader("–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            st.dataframe(st.session_state.merged_data.head(), use_container_width=True)
            
            # –†–∞—Å—á–µ—Ç group_number
            st.subheader("–†–∞—Å—á–µ—Ç group_number")
            st.caption("group_number —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö 'coll' –∏ 'well'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            missing_cols = []
            if 'well' not in st.session_state.merged_data.columns:
                missing_cols.append('well')
            
            if missing_cols:
                st.warning(f"‚ö†Ô∏è –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ group_number –Ω—É–∂–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_cols)}")
            else:
                # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                available_coll_columns = [col for col in st.session_state.merged_data.columns 
                                        if col not in ['well', 'DEPTH', 'group_number']]
                
                if 'coll' in available_coll_columns:
                    default_coll_col = 'coll'
                else:
                    default_coll_col = available_coll_columns[0] if available_coll_columns else None
                
                if default_coll_col:
                    coll_column = st.selectbox(
                        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (–∞–Ω–∞–ª–æ–≥ 'coll'):",
                        options=available_coll_columns,
                        index=available_coll_columns.index(default_coll_col) if default_coll_col in available_coll_columns else 0
                    )
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É –≤ session_state
                    st.session_state.selected_coll_column = coll_column
                    
                    if 'group_number' not in st.session_state.merged_data.columns:
                        if st.button("üîÑ –†–∞—Å—Å—á–∏—Ç–∞—Ç—å group_number"):
                            with st.spinner("–†–∞—Å—á–µ—Ç group_number..."):
                                try:
                                    st.session_state.merged_data = calculate_group_number(st.session_state.merged_data, coll_column)
                                    st.success("‚úÖ group_number —Ä–∞—Å—Å—á–∏—Ç–∞–Ω!")
                                except Exception as e:
                                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ group_number: {str(e)}")
                    else:
                        st.success("‚úÖ group_number —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω")
                        if st.button("üîÑ –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å group_number"):
                            with st.spinner("–ü–µ—Ä–µ—Å—á–µ—Ç group_number..."):
                                try:
                                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π group_number
                                    st.session_state.merged_data = st.session_state.merged_data.drop('group_number', axis=1)
                                    st.session_state.merged_data = calculate_group_number(st.session_state.merged_data, coll_column)
                                    st.success("‚úÖ group_number –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω!")
                                except Exception as e:
                                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å—á–µ—Ç–µ group_number: {str(e)}")
                else:
                    st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º")
            well_stats = st.session_state.merged_data.groupby('well').agg({
                'DEPTH': ['count', 'min', 'max'],
                **{col: 'count' for col in selected_columns if col in st.session_state.merged_data.columns}
            }).round(2)
            st.dataframe(well_stats, use_container_width=True)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º
            if 'group_number' in st.session_state.merged_data.columns:
                st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –∫–æ–ª–æ–Ω–∫—É, –∫–æ—Ç–æ—Ä—É—é –≤—ã–±—Ä–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                if (st.session_state.selected_coll_column and 
                    st.session_state.selected_coll_column in st.session_state.merged_data.columns):
                    coll_col_for_stats = st.session_state.selected_coll_column
                else:
                    # Fallback: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                    available_coll_columns = [col for col in st.session_state.merged_data.columns 
                                            if col not in ['well', 'DEPTH', 'group_number']]
                    
                    if 'coll' in available_coll_columns:
                        coll_col_for_stats = 'coll'
                    elif 'COLL' in available_coll_columns:
                        coll_col_for_stats = 'COLL'
                    elif available_coll_columns:
                        coll_col_for_stats = available_coll_columns[0]
                    else:
                        coll_col_for_stats = None
                
                if coll_col_for_stats:
                    group_stats = st.session_state.merged_data.groupby('group_number').agg({
                        'well': 'first',
                        coll_col_for_stats: 'first',
                        'DEPTH': ['count', 'min', 'max']
                    }).round(2)
                    st.dataframe(group_stats.head(10), use_container_width=True)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π –∫–æ–ª–æ–Ω–∫–∏, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    group_stats = st.session_state.merged_data.groupby('group_number').agg({
                        'well': 'first',
                        'DEPTH': ['count', 'min', 'max']
                    }).round(2)
                    st.dataframe(group_stats.head(10), use_container_width=True)

with tab3:
    st.header("–ê–≥–ª–æ–º–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥")
    
    if not BOOSTING_AVAILABLE:
        st.error("‚ùå –ú–æ–¥—É–ª—å –∞–≥–ª–æ–º–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª agglomerative_boosting.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ")
    else:
        create_boosting_interface()

with tab4:
    st.header("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –≤ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä—ã")
    
    if st.session_state.merged_data.empty:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ")
    else:
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
        
        # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        available_group_columns = [col for col in st.session_state.merged_data.columns 
                                 if col not in ['well', 'DEPTH', 'group_number']]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        default_group_col = None
        for preferred_col in ['–∫–æ–ª–ª–µ–∫—Ç–æ—Ä', 'coll', 'COLL', 'coll_type']:
            if preferred_col in available_group_columns:
                default_group_col = preferred_col
                break
        
        if not default_group_col and available_group_columns:
            default_group_col = available_group_columns[0]
        
        if default_group_col:
            group_column = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (—Ä–∞—Å—á–µ—Ç group_number):",
                options=available_group_columns,
                index=available_group_columns.index(default_group_col) if default_group_col in available_group_columns else 0,
                help="–ü–æ —ç—Ç–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É –±—É–¥—É—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å—Å—è —Ç–æ—á–∫–∏ –≤ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä—ã"
            )
        else:
            st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏")
            group_column = None
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        st.subheader("–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        numeric_columns = [col for col in st.session_state.merged_data.columns 
                          if pd.api.types.is_numeric_dtype(st.session_state.merged_data[col]) 
                          and col not in ['well', 'DEPTH', 'group_number', 'top', 'bottom', 'h']]
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º LAS –∫—Ä–∏–≤—ã–µ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–Ω–æ –≤–∫–ª—é—á–∞–µ–º COLL)
        service_columns = ['well', 'DEPTH', 'group_number', 'top', 'bottom', 'h', 'coll', '–∫–æ–ª–ª–µ–∫—Ç–æ—Ä']
        
        # –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª—É–∂–µ–±–Ω—ã–º–∏ (–≤–∫–ª—é—á–∞—è COLL)
        default_las_curves = [col for col in numeric_columns if col not in service_columns]
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
        categorical_columns = [col for col in st.session_state.merged_data.columns 
                              if not pd.api.types.is_numeric_dtype(st.session_state.merged_data[col]) 
                              and col not in ['well', 'group_number']]
        
        # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**LAS –∫—Ä–∏–≤—ã–µ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è:**")
            selected_las_curves = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ LAS –∫—Ä–∏–≤—ã–µ:",
                options=default_las_curves,
                default=default_las_curves,
                help="–≠—Ç–∏ –∫—Ä–∏–≤—ã–µ –±—É–¥—É—Ç —É—Å—Ä–µ–¥–Ω–µ–Ω—ã –ø–æ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞–º"
            )
        
        with col2:
            st.write("**–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**")
            selected_categorical = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:",
                options=categorical_columns,
                default=[],  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ
                help="–î–ª—è —ç—Ç–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±—É–¥–µ—Ç –≤–∑—è—Ç–æ –º–æ–¥–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
            )
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫—Ä–∏–≤—ã—Ö
        st.subheader("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫—Ä–∏–≤—ã—Ö")
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("LAS –∫—Ä–∏–≤—ã–µ", len(default_las_curves))
            if default_las_curves:
                st.caption(f"–ù–∞–π–¥–µ–Ω–æ: {', '.join(default_las_curves[:5])}{'...' if len(default_las_curves) > 5 else ''}")
        
        with col2:
            st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ", len(categorical_columns))
            if categorical_columns:
                st.caption(f"–ù–∞–π–¥–µ–Ω–æ: {', '.join(categorical_columns[:3])}{'...' if len(categorical_columns) > 3 else ''}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ session_state
        st.session_state.selected_las_curves = selected_las_curves
        st.session_state.selected_categorical = selected_categorical
        
        if st.button("üìä –°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤"):
            with st.spinner("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö..."):
                try:
                    st.session_state.aggregated_data = aggregate_to_collectors(
                        st.session_state.merged_data, 
                        group_column
                    )
                    st.success(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ —Å–æ–∑–¥–∞–Ω–∞: {len(st.session_state.aggregated_data)} –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {str(e)}")
        
        if not st.session_state.aggregated_data.empty:
            st.subheader("–¢–∞–±–ª–∏—Ü–∞ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
            st.subheader("üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_collectors = len(st.session_state.aggregated_data)
            st.info(f"üìä –í—Å–µ–≥–æ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {total_collectors}")
            
            # –§–∏–ª—å—Ç—Ä –ø–æ h < 0.4
            if 'h' in st.session_state.aggregated_data.columns:
                initial_count = len(st.session_state.aggregated_data)
                filtered_data = st.session_state.aggregated_data[st.session_state.aggregated_data['h'] >= 0.4]
                filtered_count = len(filtered_data)
                
                if initial_count != filtered_count:
                    st.info(f"üîç –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {initial_count - filtered_count} –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ —Å h < 0.4. –û—Å—Ç–∞–ª–æ—Å—å {filtered_count} –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤.")
                    display_data = filtered_data
                else:
                    st.info("‚úÖ –í—Å–µ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä—ã –∏–º–µ—é—Ç h >= 0.4")
                    display_data = st.session_state.aggregated_data
            else:
                st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'h' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
                display_data = st.session_state.aggregated_data
            
            # –§–∏–ª—å—Ç—Ä –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
            if group_column and group_column in display_data.columns:
                st.write(f"**–§–∏–ª—å—Ç—Ä –ø–æ {group_column}:**")
                
                # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                unique_values = display_data[group_column].unique()
                unique_values = sorted([v for v in unique_values if pd.notna(v)])
                
                if unique_values:
                    # –í—ã–±–æ—Ä –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                    selected_values = st.multiselect(
                        f"–í—ã–±–µ—Ä–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è {group_column} –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
                        options=unique_values,
                        default=unique_values,
                        help=f"–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä—ã —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ {group_column}"
                    )
                    
                    if selected_values:
                        display_data = display_data[display_data[group_column].isin(selected_values)]
                        st.info(f"üìä –ü–æ–∫–∞–∑–∞–Ω–æ {len(display_data)} –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ —Å {group_column} –≤ {selected_values}")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º
                        if len(selected_values) > 1:
                            value_counts = display_data[group_column].value_counts()
                            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º:**")
                            for value, count in value_counts.items():
                                st.write(f"- {value}: {count} –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
                    else:
                        st.warning("‚ö†Ô∏è –ù–µ –≤—ã–±—Ä–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                        display_data = pd.DataFrame()  # –ü—É—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞
                else:
                    st.warning(f"‚ö†Ô∏è –í –∫–æ–ª–æ–Ω–∫–µ {group_column} –Ω–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            else:
                st.info("‚ÑπÔ∏è –ì—Ä—É–ø–ø–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            if not display_data.empty:
                st.dataframe(display_data, use_container_width=True)
                
                # –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            csv_buf = io.StringIO()
            display_data.to_csv(csv_buf, index=False, encoding="utf-8")
            st.download_button(
                    "üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ (CSV)",
                csv_buf.getvalue().encode("utf-8"),
                    "filtered_collectors_table.csv",
                "text/csv"
                )
        else:
                st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            
            # –≠–∫—Å–ø–æ—Ä—Ç –ø–æ–ª–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤)
        st.subheader("üì• –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
            csv_buf = io.StringIO()
            st.session_state.aggregated_data.to_csv(csv_buf, index=False, encoding="utf-8")
            st.download_button(
                "üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ (CSV)",
                csv_buf.getvalue().encode("utf-8"),
                "full_collectors_table.csv",
                "text/csv",
                help="–°–∫–∞—á–∞—Ç—å –≤—Å–µ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä—ã –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"
            )

with tab4:
    st.header("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
    
    if st.session_state.aggregated_data.empty:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —Ç–∞–±–ª–∏—Ü—É –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
    else:
        df = st.session_state.aggregated_data.copy()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ group_number
        if "group_number" not in df.columns:
            st.error("‚ùå –ö–æ–ª–æ–Ω–∫–∞ 'group_number' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        else:
            id_col = "group_number"
            
            # –ü—Ä–∏–∑–Ω–∞–∫–∏
            num_all, cat_all = get_numeric_and_categorical_columns(df, id_col)
            if not num_all and not cat_all:
                st.error("‚ùå –ù–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫—Ä–æ–º–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞")
            else:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º LAS –∫—Ä–∏–≤—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                # LAS –∫—Ä–∏–≤—ã–µ –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                las_curves = [
                    "GR", "GK", "GK_NORM", "NK", "DTP", "DTP_NORM", "DT", "RHOB", "NPHI", 
                    "SP", "LLD", "LLS", "MSFL", "BK", "log_BK", "log_BK_NORM", "RT", "RXO",
                    "CALI", "CGR", "PEF", "DRHO", "LITH", "LITHO", "LITHOLOGY"
                ]
                
                # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                service_columns = ['top', 'bottom', 'h', 'group_number', 'well']
                filtered_num_all = [c for c in num_all if c not in service_columns]
                
                # –ù–∞—Ö–æ–¥–∏–º LAS –∫—Ä–∏–≤—ã–µ –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                available_las_curves = [c for c in filtered_num_all if c in las_curves or 
                                      any(las_name in c.upper() for las_name in ["GR", "GK", "NK", "DTP", "DT", "RHOB", "NPHI", "SP", "LLD", "LLS", "MSFL", "BK", "RT", "RXO", "CALI", "CGR", "PEF", "DRHO"])]
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å LAS –∫—Ä–∏–≤—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ
                if available_las_curves:
                    default_nums = available_las_curves
                    st.info(f"üîç –ù–∞–π–¥–µ–Ω—ã LAS –∫—Ä–∏–≤—ã–µ: {', '.join(available_las_curves)}")
                else:
                    preferred_numeric = [
                        "GK_NORM", "NK", "DTP_NORM", "log_BK_NORM", "frac_rf",
                        "dis_frac_rfn", "por_rf", "kvo_rf", "SAT_rf",
                        "log10Kpr_tim", "log10Kpr_rf",
                    ]
                    default_nums = [c for c in preferred_numeric if c in filtered_num_all] or filtered_num_all
                
                left, mid, right = st.columns(3)
                with left:
                    sel_num = st.multiselect("–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏", options=num_all, default=default_nums, key="boosting_numeric")
                with mid:
                    sel_cat = st.multiselect("–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏", options=cat_all, default=[], key="boosting_categorical")
                with right:
                    standardize = st.checkbox("–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö", value=True, key="boosting_standardize")
                    metric = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞", options=["euclidean", "cityblock", "cosine"], index=0, key="boosting_metric")
                    linkage_method = st.selectbox("–õ–∏–Ω–∫–æ–≤–∫–∞", options=["ward", "average", "complete", "single"], index=0, key="boosting_linkage")
                
                if len(sel_num) + len(sel_cat) == 0:
                    st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫")
                else:
                    # –û—á–∏—Å—Ç–∫–∞ –ø–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É
                    df = df.dropna(subset=[id_col]).reset_index(drop=True)
                    
                    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
                    X, labels = compute_features(df, id_col, sel_num, sel_cat, standardize)
                    
                    st.subheader("–°—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞")
                    
                    # –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # –í—ã–±–æ—Ä –ø–æ —Å–∫–≤–∞–∂–∏–Ω–µ
                        if 'well' in df.columns:
                            available_wells = df['well'].unique()
                            selected_well = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å–∫–≤–∞–∂–∏–Ω—É:", options=available_wells)
                            
                            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å–∫–≤–∞–∂–∏–Ω–µ
                            well_filtered_df = df[df['well'] == selected_well]
                            well_labels = well_filtered_df[id_col].unique()
                        else:
                            well_labels = labels
                            selected_well = None
                    
                    with col2:
                        # –í—ã–±–æ—Ä –ø–æ –≥–ª—É–±–∏–Ω–µ (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏ top/bottom)
                        if 'top' in df.columns and 'bottom' in df.columns:
                            if selected_well:
                                depth_options = well_filtered_df[['top', 'bottom']].dropna()
                            else:
                                depth_options = df[['top', 'bottom']].dropna()
                            
                            if not depth_options.empty:
                                min_depth = depth_options['top'].min()
                                max_depth = depth_options['bottom'].max()
                                
                                depth_range = st.slider(
                                    "–î–∏–∞–ø–∞–∑–æ–Ω –≥–ª—É–±–∏–Ω:",
                                    min_value=float(min_depth),
                                    max_value=float(max_depth),
                                    value=(float(min_depth), float(max_depth)),
                                    step=0.1
                                )
                                
                                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≥–ª—É–±–∏–Ω–µ
                                if selected_well:
                                    depth_filtered_df = well_filtered_df[
                                        (well_filtered_df['top'] >= depth_range[0]) & 
                                        (well_filtered_df['bottom'] <= depth_range[1])
                                    ]
                                else:
                                    depth_filtered_df = df[
                                        (df['top'] >= depth_range[0]) & 
                                        (df['bottom'] <= depth_range[1])
                                    ]
                                
                                depth_labels = depth_filtered_df[id_col].unique()
                            else:
                                depth_labels = well_labels
                        else:
                            depth_labels = well_labels
                    
                    # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
                    if len(depth_labels) > 0:
                        target_label = st.selectbox("–ó–Ω–∞—á–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (group_number):", options=depth_labels)
                    idx_by_label = {l: i for i, l in enumerate(labels)}
                    target_idx = idx_by_label[target_label]
                    
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–µ
                        target_info = df[df[id_col] == target_label].iloc[0]
                        st.info(f"üéØ –í—ã–±—Ä–∞–Ω –∫–æ–ª–ª–µ–∫—Ç–æ—Ä {target_label}: —Å–∫–≤–∞–∂–∏–Ω–∞ {target_info.get('well', 'N/A')}, "
                               f"–≥–ª—É–±–∏–Ω–∞ {target_info.get('top', 'N/A')}-{target_info.get('bottom', 'N/A')} –º")
                    else:
                        st.error("‚ùå –ù–µ—Ç –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º")
                        target_label = None
                        target_idx = None
                    
                    # –¢–æ–ø-10 –ø–æ—Ö–æ–∂–∏—Ö (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ç–æ—Ä)
                    if target_label is not None:
                    neighbor_labels, neighbor_dists = compute_top_k_similar(X, labels, target_label, metric, 10)
                    neighbor_indices = [idx_by_label[l] for l in neighbor_labels]
                    
                    # –¢–∞–±–ª–∏—Ü–∞ –ø–æ—Ö–æ–∂–∏—Ö
                    extra_cols = [c for c in ["well", "top", "bottom", 'BF', "TEST", "TYPE"] if c in df.columns]
                    neighbors_extra = df.loc[neighbor_indices, extra_cols] if extra_cols else pd.DataFrame(index=neighbor_indices)
                    neighbors_df = pd.DataFrame({id_col: neighbor_labels, "distance": neighbor_dists})
                    if not neighbors_extra.empty:
                        neighbors_df = pd.concat([neighbors_df.reset_index(drop=True), neighbors_extra.reset_index(drop=True)], axis=1)
                    if "well" in neighbors_df.columns:
                        neighbors_df = neighbors_df[[id_col, "well"] + [c for c in neighbors_df.columns if c not in [id_col, "well"]]]
                    neighbors_df = neighbors_df.sort_values("distance", ascending=True, ignore_index=True)
                    
                    st.write("10 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö:")
                    st.dataframe(neighbors_df, use_container_width=True)
                    
                    # –≠–∫—Å–ø–æ—Ä—Ç —Ç–æ–ø-10
                    buf = io.StringIO()
                    neighbors_df.to_csv(buf, index=False, encoding="utf-8")
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å —Ç–æ–ø-10 (CSV)", buf.getvalue().encode("utf-8"), "top10_neighbors.csv", "text/csv")
                        
                        # –î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ –∏ PCA –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤ (–ø–æ –æ–±—Ä–∞–∑—Ü—É best_well_hc.py)
                        st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏")
                        
                        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                        subset_indices = [target_idx] + neighbor_indices
                        subset_labels = [target_label] + neighbor_labels
                        X_subset = X[subset_indices, :]
                        
                        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∏—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: group_number | well | Q (–∫–∞–∫ –≤ best_well_hc.py)
                        def format_display_label(row, id_value):
                            parts = [str(id_value)]
                            if "well" in row.index and pd.notna(row["well"]) and str(row["well"]).strip() != "":
                                parts.append(str(row["well"]))
                            if "Q" in row.index and pd.notna(row["Q"]):
                                try:
                                    q = float(row["Q"])
                                    parts.append(f"Q={q:.3g}")
                                except Exception:
                                    parts.append(f"Q={row['Q']}")
                            return " | ".join(parts)
                        
                        def make_display_labels(indices):
                            out = []
                            for i in indices:
                                orig_id = str(df.iloc[i][id_col])
                                out.append(format_display_label(df.iloc[i], orig_id))
                            return out
                        
                        subset_display_labels = make_display_labels(subset_indices)
                        target_display_label = subset_display_labels[0]
                        
                        # –î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ –∏ PCA –≤ –¥–≤—É—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
                        col_left, col_right = st.columns(2)
                        
                        with col_left:
                            # –î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ (–ø–æ –æ–±—Ä–∞–∑—Ü—É best_well_hc.py)
                            try:
                                metric_for_linkage = "euclidean" if linkage_method == "ward" else metric
                                Z = linkage(X_subset, method=linkage_method, metric=metric_for_linkage)
                                
                                fig_dendro, ax_dendro = plt.subplots(figsize=(9, 7), dpi=150)
                                dendrogram(Z, labels=subset_display_labels, leaf_rotation=90, leaf_font_size=12, ax=ax_dendro)
                                ax_dendro.set_title("–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ (—Ü–µ–ª–µ–≤–æ–π + 10 –ø–æ—Ö–æ–∂–∏—Ö)")
                                ax_dendro.set_ylabel("–î–∏—Å—Ç–∞–Ω—Ü–∏—è")
                                
                                # –í—ã–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ç–æ—Ä –∫—Ä–∞—Å–Ω—ã–º —Ü–≤–µ—Ç–æ–º
                                for tick in ax_dendro.get_xmajorticklabels():
                                    if tick.get_text() == target_display_label:
                                        tick.set_color("crimson")
                                        tick.set_fontweight("bold")
                                    else:
                                        tick.set_color("black")
                                
                                fig_dendro.tight_layout()
                                st.pyplot(fig_dendro, use_container_width=True)
                                
                                # –≠–∫—Å–ø–æ—Ä—Ç –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—ã
                                png_buf = io.BytesIO()
                                fig_dendro.savefig(png_buf, format="png", bbox_inches="tight", dpi=200)
                                st.download_button("–°–∫–∞—á–∞—Ç—å –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—É (PNG)", png_buf.getvalue(), "dendrogram_top10.png", "image/png")
                                
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—ã: {str(e)}")
                    
                    with col_right:
                            # PCA –±–∏–ø–ª–æ—Ç (–ø–æ –æ–±—Ä–∞–∑—Ü—É best_well_hc.py)
                            try:
                                if len(sel_num) < 2:
                                    raise ValueError("–î–ª—è PCA –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞.")
                                
                                from sklearn.decomposition import PCA
                                from sklearn.impute import SimpleImputer
                                
                                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                                num_imputer = SimpleImputer(strategy="median")
                                scaler = StandardScaler() if standardize else None
                                
                                X_num_full = num_imputer.fit_transform(df[sel_num])
                                if scaler:
                                    X_num_full = scaler.fit_transform(X_num_full)
                                X_num_subset = X_num_full[subset_indices, :]
                                
                                if np.allclose(X_num_subset.std(axis=0), 0):
                                    st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è PCA.")
                                else:
                                    pca = PCA(n_components=2, random_state=0)
                                    scores = pca.fit_transform(X_num_subset)
                                    loadings = pca.components_.T
                                    evr = pca.explained_variance_ratio_
                                    
                                    fig_pca, ax_pca = plt.subplots(figsize=(5, 6), dpi=150)
                                    
                                    # –¢–æ—á–∫–∏: –ø–æ—Ö–æ–∂–∏–µ (—Å–µ—Ä—ã–µ) –∏ —Ü–µ–ª–µ–≤–æ–π (–∫—Ä–∞—Å–Ω–∞—è –∑–≤–µ–∑–¥–∞)
                                    ax_pca.scatter(scores[1:, 0], scores[1:, 1], c="gray", s=60, edgecolors="k", alpha=0.9, label="–ü–æ—Ö–æ–∂–∏–µ")
                                    ax_pca.scatter(scores[0, 0], scores[0, 1], c="crimson", s=100, edgecolors="k", marker="*", label="–¶–µ–ª–µ–≤–æ–π")
                                    
                                    # –ü–æ–¥–ø–∏—Å–∏ —Ç–æ—á–µ–∫
                                    for i, (x, y) in enumerate(scores):
                                        ax_pca.text(x, y, subset_display_labels[i],
                                                  fontsize=9 if i == 0 else 8, ha="left", va="bottom",
                                                  color="crimson" if i == 0 else "black",
                                                  fontweight="bold" if i == 0 else "normal")
                                    
                                    # –°—Ç—Ä–µ–ª–∫–∏ –Ω–∞–≥—Ä—É–∑–æ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
                                    if len(sel_num) > 0:
                                        arrow_scale = np.max(np.linalg.norm(scores, axis=1)) * 1.3
                                        for j, feature in enumerate(sel_num):
                                            vx, vy = loadings[j, 0] * arrow_scale, loadings[j, 1] * arrow_scale
                                            ax_pca.arrow(0, 0, vx, vy, color="tab:blue",
                                                       width=0.0006, head_width=0.012, head_length=0.02,
                                                       length_includes_head=True, alpha=0.9)
                                            ax_pca.text(vx, vy, feature, fontsize=8, color="tab:blue", ha="center", va="center")
                                    
                                    # –°–µ—Ç–∫–∞ –∏ –æ—Å–∏
                                    ax_pca.axhline(0, color="lightgray", linewidth=1)
                                    ax_pca.axvline(0, color="lightgray", linewidth=1)
                                    ax_pca.set_xlabel(f"PC1 ({evr[0]*100:.1f}%)")
                                    ax_pca.set_ylabel(f"PC2 ({evr[1]*100:.1f}%)")
                                    ax_pca.legend(fontsize=8)
                                    ax_pca.set_title("PCA –±–∏–ø–ª–æ—Ç (—Ü–µ–ª–µ–≤–æ–π + 10 –ø–æ—Ö–æ–∂–∏—Ö)")
                                    
                                    fig_pca.tight_layout()
                                    st.pyplot(fig_pca, use_container_width=True)
                                    
                                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PCA
                                    st.info(f"üìä PCA –æ–±—ä—è—Å–Ω—è–µ—Ç {pca.explained_variance_ratio_.sum()*100:.1f}% –æ–±—â–µ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
                                    
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PCA: {str(e)}")
                    st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ç–æ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏")

with tab5:
    st.header("üìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤")
    
    if st.session_state.aggregated_data.empty:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —Ç–∞–±–ª–∏—Ü—É –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤")
    else:
        df = st.session_state.aggregated_data.copy()
        
        if "group_number" not in df.columns:
            st.error("‚ùå –ö–æ–ª–æ–Ω–∫–∞ 'group_number' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        else:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ—Ç—á—ë—Ç–∞
            st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # –í—ã–±–æ—Ä —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                numeric_columns = [col for col in df.columns 
                                 if pd.api.types.is_numeric_dtype(df[col]) 
                                 and col not in ['group_number', 'top', 'bottom', 'h']]
                
                sel_num = st.multiselect(
                    "–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏",
                    options=numeric_columns,
                    default=numeric_columns[:5] if len(numeric_columns) > 5 else numeric_columns,
                    help="–í—ã–±–µ—Ä–∏—Ç–µ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                    key="report_numeric"
                )
            
            with col2:
                # –í—ã–±–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                categorical_columns = [col for col in df.columns 
                                     if not pd.api.types.is_numeric_dtype(df[col]) 
                                     and col not in ['group_number', 'well']]
                
                sel_cat = st.multiselect(
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏",
                    options=categorical_columns,
                    default=[],
                    help="–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –±—É–¥—É—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –≤ one-hot encoding",
                    key="report_categorical"
                )
            
            with col3:
                standardize = st.checkbox("–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö", value=True, key="report_standardize")
                metric = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è", 
                                    options=["euclidean", "cityblock", "cosine"], 
                                    index=0, key="report_metric")
                linkage_method = st.selectbox("–ú–µ—Ç–æ–¥ —Å–≤—è–∑—ã–≤–∞–Ω–∏—è", 
                                            options=["ward", "average", "complete", "single"], 
                                            index=0, key="report_linkage")
                
                if linkage_method == "ward" and metric != "euclidean":
                    st.info("‚ÑπÔ∏è Ward —Ç—Ä–µ–±—É–µ—Ç –µ–≤–∫–ª–∏–¥–æ–≤—É –º–µ—Ç—Ä–∏–∫—É")
            
            if len(sel_num) + len(sel_cat) == 0:
                st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫")
            else:
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á—ë—Ç–∞: COLL == 1 –∏ TEST != nan
                st.subheader("üìã –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á—ë—Ç–∞")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                has_coll = 'COLL' in df.columns
                has_test = 'TEST' in df.columns
                
                if not has_coll:
                    st.error("‚ùå –ö–æ–ª–æ–Ω–∫–∞ 'COLL' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                elif not has_test:
                    st.error("‚ùå –ö–æ–ª–æ–Ω–∫–∞ 'TEST' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                else:
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
                    initial_count = len(df)
                    
                    # COLL == 1
                    coll_filtered = df[df['COLL'] == 1]
                    coll_count = len(coll_filtered)
                    
                    # TEST is not NaN
                    test_filtered = coll_filtered[~coll_filtered['TEST'].isna()]
                    final_count = len(test_filtered)
                    
                    st.info(f"üìä –ò—Å—Ö–æ–¥–Ω–æ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤: {initial_count}")
                    st.info(f"üîç –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ COLL == 1: {coll_count}")
                    st.info(f"‚úÖ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ TEST –Ω–µ –ø—É—Å—Ç–æ–π: {final_count}")
                    
                    if final_count == 0:
                        st.warning("‚ö†Ô∏è –ù–µ—Ç –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º –æ—Ç—á—ë—Ç–∞")
            else:
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                        st.write("**–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:**")
                        display_cols = ['group_number', 'well', 'top', 'bottom', 'h', 'COLL', 'TEST']
                        available_display_cols = [col for col in display_cols if col in test_filtered.columns]
                        st.dataframe(test_filtered[available_display_cols], use_container_width=True)
                        
                        # –ö–Ω–æ–ø–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞
                        if st.button("üìÑ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç", type="primary"):
                            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞..."):
                                try:
                                    # –°–æ–∑–¥–∞—ë–º –æ—Ç—á—ë—Ç
                                    report_html = generate_clustering_report(
                                        test_filtered, sel_num, sel_cat, standardize, 
                                        metric, linkage_method, 'group_number'
                                    )
                                    
                                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –æ—Ç—á—ë—Ç–∞
                                    st.subheader("üìÑ –ü—Ä–µ–≤—å—é –æ—Ç—á—ë—Ç–∞")
                                    st.components.v1.html(report_html, height=600, scrolling=True)
                                    
                                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                                    st.download_button(
                                        "üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (HTML)",
                                        report_html,
                                        "clustering_report.html",
                                        "text/html",
                                        help="–û—Ç—á—ë—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ HTML —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏"
                                    )
                                    
                                    st.success("‚úÖ –û—Ç—á—ë—Ç —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω!")
                                    
                                except Exception as e:
                                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞: {str(e)}")
                                    st.exception(e)
